{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BYjS4fm1FzC",
        "outputId": "363aa861-04bc-4b43-baaa-78a7813b359f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abdalrhman Fouad Osama Attia\n",
            "4221155\n",
            "AI323-Computational NeuroScience Assignment Report Lecture 2\n"
          ]
        }
      ],
      "source": [
        "print(\"Abdalrhman Fouad Osama Attia\")\n",
        "print(\"4221155\")\n",
        "print(\"AI323-Computational NeuroScience Assignment Report Lecture 2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "def sigmoid_derivative(x):\n",
        "  return x * (1 - x)\n",
        "inputs = [[0.05, 0.10]]\n",
        "expected_output = [[0.01, 0.99]]\n",
        "learning_rate = 0.5\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 2\n",
        "output_layer_size = 2\n",
        "hidden_weights = [[0.15, 0.25],[0.20, 0.30]]\n",
        "output_weights = [[0.40, 0.50],[0.45, 0.55]]\n",
        "hidden_bias = [0.35, 0.35]\n",
        "output_bias = [0.60, 0.60]\n",
        "for epoch in range(10000):\n",
        "  hidden_layer_input = [0, 0]\n",
        "for i in range(hidden_layer_size):\n",
        "  hidden_layer_input[i] = (inputs[0][0] * hidden_weights[0][i]) + (inputs[0][1] * hidden_weights[1][i]) + hidden_bias[i]\n",
        "  hidden_layer_output = [sigmoid(h) for h in hidden_layer_input]\n",
        "  output_layer_input = [0, 0]\n",
        "for i in range(output_layer_size):\n",
        "  output_layer_input[i] = (hidden_layer_output[0] * output_weights[0][i]) + (hidden_layer_output[1] * output_weights[1][i]) + output_bias[i]\n",
        "  output_layer_output = [sigmoid(o) for o in output_layer_input]\n",
        "output_errors = [expected_output[0][i] - output_layer_output[i] for i in range(output_layer_size)]\n",
        "output_gradients = [sigmoid_derivative(output_layer_output[i]) * output_errors[i] for i in range(output_layer_size)]\n",
        "for i in range(output_layer_size):\n",
        "  for j in range(hidden_layer_size):\n",
        "    output_weights[j][i] += learning_rate * output_gradients[i] * hidden_layer_output[j]\n",
        "    output_bias[i] += learning_rate * output_gradients[i]\n",
        "hidden_errors = [sum(output_gradients[k] * output_weights[j][k] for k in range(output_layer_size)) for j in range(hidden_layer_size)]\n",
        "hidden_gradients = [sigmoid_derivative(hidden_layer_output[i]) * hidden_errors[i] for i in range(hidden_layer_size)]\n",
        "for i in range(hidden_layer_size):\n",
        "  for j in range(input_layer_size):\n",
        "    hidden_weights[j][i] += learning_rate * hidden_gradients[i] * inputs[0][j]\n",
        "    hidden_bias[i] += learning_rate * hidden_gradients[i]\n",
        "print(\"Final Output after training:\")\n",
        "print(output_layer_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Ly6UNz1sUH",
        "outputId": "e4995485-6fba-4080-eef4-3fa1c82cf93b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Output after training:\n",
            "[0.7513650695523157, 0.7729284653214625]\n"
          ]
        }
      ]
    }
  ]
}